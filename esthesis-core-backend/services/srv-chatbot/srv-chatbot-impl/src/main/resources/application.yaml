quarkus:
  application:
    name: esthesis-core-srv-chatbot
  devservices:
    enabled: false
  http:
    auth:
      proactive: false
    idle-timeout: 5m
  websockets-next:
    server:
      supported-subprotocols: bearer-token-carrier
      propagate-subprotocol-headers: true
      auto-ping-interval: 5m
  log:
    min-level: TRACE
    console:
      format: "%d{HH:mm:ss} %-5p traceId=%X{traceId}, parentId=%X{parentId}, spanId=%X{spanId}, sampled=%X{sampled} [%c{2.}] (%t) %s%e%n"
    handler:
      gelf:
        enabled: false
        include-full-mdc: true
        skip-hostname-resolution: false
        additional-field:
          platform:
            value: esthesis
          module:
            value: esthesis-core
          type:
            value: API
          service:
            value: ${quarkus.application.name}
  langchain4j:
    chat-model:
      provider: ollama
    embedding-model:
      provider: ollama
    openai:
      chat-model:
        model-name: gpt-3.5-turbo
        log-requests: false
        log-responses: false
        temperature: 0.1
      embedding-model:
        log-requests: false
        log-responses: false
    ollama:
      base-url: "http://ollama:11434"
      timeout: 60s
      log-requests: false
      log-responses: false
      chat-model:
        model-id: "qwen3:0.6b"
        temperature: 0.1
        log-requests: false
        log-responses: false
      embedding-model:
        model-id: "nomic-embed-text"
        temperature: 0.1
        log-requests: false
        log-responses: false
    easy-rag:
      path: src/main/resources/rag
  banner:
    enabled: false
  otel:
    sdk:
      disabled: true
  rest-client:
    DeviceResource:
      url: http://esthesis-core-srv-device-service:8080
      scope: Singleton
